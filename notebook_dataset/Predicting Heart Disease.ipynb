{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HEART DISEASE PREDICTION PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install fsspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = 'heartDisease.csv'\n",
    "data = pd.read_csv(filePath)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"(Rows, columns): \" + str(data.shape))\n",
    "data.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Missing Values\n",
    "print(data.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  correlation matrix\n",
    "\n",
    "corr = data.corr()\n",
    "plt.subplots(figsize=(15,10))\n",
    "sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns, annot=True, cmap=sns.diverging_palette(220, 20, as_cmap=True))\n",
    "sns.heatmap(corr, xticklabels=corr.columns,\n",
    "            yticklabels=corr.columns, \n",
    "            annot=True,\n",
    "            cmap=sns.diverging_palette(220, 20, as_cmap=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A positive correlation can be seen between chest pain & target .So the more severe chest pain could result in a greater chance of having heart disease. Cp (chest pain), is a ordinal feature with 4 values: Value 1: typical angina ,Value 2: atypical angina, Value 3: non-anginal pain , Value 4: asymptomatic. \n",
    "\n",
    "Also we have a negative correlation between exercise induced angina & our predictor.Due to Excessive excercise heart requires more blood,but narrowed arteries slow down blood flow. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pairplots helps to vizualize  the correlations between all variables . Here we will be plotting several features and their correlation and autocorrelation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subData = data[['age','trestbps','chol','thalach','oldpeak']]\n",
    "sns.pairplot(subData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = [\"target\",\n",
    "\"sex\",\n",
    "\"cp\",\n",
    "\"fbs\",\n",
    "\"restecg\",\n",
    "\"exang\",\n",
    "\"slope\",\n",
    "\"ca\",\n",
    "\"thal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,20))\n",
    "for i in range(1,10):\n",
    "    labels = data[categorical[i-1]].value_counts().index\n",
    "    sizes  = data[categorical[i-1]].value_counts().values\n",
    "    plt.subplot(5,2,i)\n",
    "    plt.pie(sizes, labels=labels, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "    plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(categorical[i-1].upper())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(10,17))\n",
    "plt.subplot(5,2,1)\n",
    "sns.kdeplot(data.loc[data[\"target\"]==1][\"age\"],color=\"green\",shade=True)\n",
    "sns.kdeplot(data.loc[data[\"target\"]==0][\"age\"],color=\"red\",shade=True)\n",
    "plt.legend([\"target:1\",\"target:0\"])\n",
    "plt.title(\"Age\".upper())\n",
    "    \n",
    "for i in range(2,9):\n",
    "    plt.subplot(5,2,i)\n",
    "    sns.boxenplot(data=data, x=categorical[i-1],y=\"age\")\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(10,17))\n",
    "plt.subplot(5,2,1)\n",
    "sns.kdeplot(data.loc[data[\"target\"]==1][\"chol\"],color=\"green\",shade=True)\n",
    "sns.kdeplot(data.loc[data[\"target\"]==0][\"chol\"],color=\"red\",shade=True)\n",
    "plt.legend([\"target:1\",\"target:0\"])\n",
    "plt.title(\"chol\".upper())\n",
    "    \n",
    "for i in range(2,9):\n",
    "    plt.subplot(5,2,i)\n",
    "    sns.boxenplot(data=data, x=categorical[i-1],y=\"chol\")\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,17))\n",
    "plt.subplot(5,2,1)\n",
    "sns.kdeplot(data.loc[data[\"target\"]==1][\"thalach\"],color=\"green\",shade=True)\n",
    "sns.kdeplot(data.loc[data[\"target\"]==0][\"thalach\"],color=\"red\",shade=True)\n",
    "plt.legend([\"target:1\",\"target:0\"])\n",
    "plt.title(\"thalach\".upper())\n",
    "    \n",
    "for i in range(2,9):\n",
    "    plt.subplot(5,2,i)\n",
    "    sns.boxenplot(data=data, x=categorical[i-1],y=\"thalach\")\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,17))\n",
    "plt.subplot(5,2,1)\n",
    "sns.kdeplot(data.loc[data[\"target\"]==1][\"oldpeak\"],color=\"green\",shade=True)\n",
    "sns.kdeplot(data.loc[data[\"target\"]==0][\"oldpeak\"],color=\"red\",shade=True)\n",
    "plt.legend([\"target:1\",\"target:0\"])\n",
    "plt.title(\"oldpeak\".upper())\n",
    "    \n",
    "for i in range(2,9):\n",
    "    plt.subplot(5,2,i)\n",
    "    sns.boxenplot(data=data, x=categorical[i-1],y=\"oldpeak\")\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X = data.drop(\"target\",axis=1)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "components = pca.fit_transform(X)\n",
    "\n",
    "components = pd.DataFrame(components)\n",
    "components[\"target\"] = data['target']\n",
    "\n",
    "plt.figure(figsize=(14,6))\n",
    "sns.scatterplot(data=pd.DataFrame(components), x=0, y=1, hue='target',palette=[\"teal\",\"maroon\"])\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.title(\"PCA\",fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"target\", y=\"oldpeak\", hue=\"slope\", kind=\"bar\", data=data);\n",
    "\n",
    "plt.title('ST depression (induced by exercise relative to rest) vs. Heart Disease',size=25)\n",
    "plt.xlabel('Heart Disease',size=20)\n",
    "plt.ylabel('ST depression',size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ST segment depression occurs because when the ventricle is at rest and therefore repolarized. If the trace in the ST segment is abnormally low below the baseline, this can lead to this Heart Disease. This is supports the plot above because low ST Depression yields people at greater risk for heart disease. While a high ST depression is considered normal & healthy. The \"slope\" hue, refers to the peak exercise ST segment, with values: 0: upsloping , 1: flat , 2: downsloping). Both positive & negative heart disease patients exhibit equal distributions of the 3 slope categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The advantages of showing the Box & Violin plots is that it showsthe basic statistics of the data, as well as its distribution. These plots are often used to compare the distribution of a given variable across some categories. \n",
    "It shows the median, IQR, & Tukeyâ€™s fence. (minimum, first quartile (Q1), median, third quartile (Q3), and maximum). In addition it can provide us with outliers in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.violinplot(x= 'target', y= 'oldpeak',hue=\"sex\", inner='quartile',data= data )\n",
    "plt.title(\"Thalach Level vs. Heart Disease\",fontsize=20)\n",
    "plt.xlabel(\"Heart Disease Target\", fontsize=16)\n",
    "plt.ylabel(\"Thalach Level\", fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.boxplot(x= 'target', y= 'thalach',hue=\"sex\", data=data )\n",
    "plt.title(\"ST depression Level vs. Heart Disease\", fontsize=20)\n",
    "plt.xlabel(\"Heart Disease Target\",fontsize=16)\n",
    "plt.ylabel(\"ST depression induced by exercise relative to rest\", fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering data by positive & negative Heart Disease patient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering data by positive Heart Disease patient \n",
    "pos_data = data[data['target']==1]\n",
    "pos_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering data by negative Heart Disease patient \n",
    "neg_data = data[data['target']==0]\n",
    "neg_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"(Positive Patients ST depression): \" + str(pos_data['oldpeak'].mean()))\n",
    "print(\"(Negative Patients ST depression): \" + str(neg_data['oldpeak'].mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"(Positive Patients thalach): \" + str(pos_data['thalach'].mean()))\n",
    "print(\"(Negative Patients thalach): \" + str(neg_data['thalach'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Machine Learning + Predictive Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split: the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = 42)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize: Standardizing the data will transform the data so that its distribution will have a mean of 0 and a standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling /Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1: Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model1 = LogisticRegression() # get instance of model\n",
    "model1.fit(x_train, y_train) # Train/Fit model \n",
    "\n",
    "y_pred1 = model1.predict(x_test) # get y predictions\n",
    "print(classification_report(y_test, y_pred1)) # output accuracy\n",
    "\n",
    "\n",
    "Accuracy_score= accuracy_score(y_test, model1.predict(x_test)) * 100\n",
    "results_df = pd.DataFrame(data=[[\"Logistic Regression\", Accuracy_score]], \n",
    "                          columns=['Model', 'Accuracy %'])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2: K-NN (K-Nearest Neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model2 = KNeighborsClassifier() # get instance of model\n",
    "model2.fit(x_train, y_train) # Train/Fit model \n",
    "\n",
    "y_pred2 = model2.predict(x_test) # get y predictions\n",
    "print(classification_report(y_test, y_pred2)) # output accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We will now cheak error for diffrent values of K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate = []\n",
    "\n",
    "# Will take some time\n",
    "for i in range(1,40):\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(x_train,y_train)\n",
    "    pred_i = knn.predict(x_test)\n",
    "    error_rate.append(np.mean(pred_i != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,40),error_rate,color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# NOW WITH K=16\n",
    "knn = KNeighborsClassifier(n_neighbors=16)\n",
    "\n",
    "knn.fit(x_train,y_train)\n",
    "pred = knn.predict(x_test)\n",
    "\n",
    "print('WITH K=16')\n",
    "print('\\n')\n",
    "print(classification_report(y_test, pred)) # output accuracy\n",
    "\n",
    "Accuracy_score= accuracy_score(y_test, knn.predict(x_test)) * 100\n",
    "results_df_2 = pd.DataFrame(data=[[\"K-nearest neighbors\", Accuracy_score]], \n",
    "                          columns=['Model', 'Accuracy %' ])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 3: SVM (Support Vector Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model3 = SVC() # get instance of model\n",
    "model3.fit(x_train, y_train) # Train/Fit model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred3 = model3.predict(x_test) # get y predictions\n",
    "print(classification_report(y_test, y_pred3)) # output accuracy\n",
    "\n",
    "test_score = accuracy_score(y_test, model3.predict(x_test)) * 100\n",
    "\n",
    "results_df_2 = pd.DataFrame(data=[[\"Support Vector Machine\", test_score]], \n",
    "                          columns=['Model', 'Accuracy %'])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 4:  Naives Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model4 = GaussianNB() # get instance of model\n",
    "model4.fit(x_train, y_train) # Train/Fit model \n",
    "\n",
    "y_pred4 = model4.predict(x_test) # get y predictions\n",
    "print(classification_report(y_test, y_pred4)) # output accuracy\n",
    "\n",
    "\n",
    "test_score = accuracy_score(y_test, model4.predict(x_test)) * 100\n",
    "\n",
    "results_df_2 = pd.DataFrame(data=[[\"Navies Bayes Classifier\", test_score]], \n",
    "                          columns=['Model', 'Accuracy %'])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 5: Decision Trees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model5 = DecisionTreeClassifier(max_depth=3,random_state=42) # get instance of model\n",
    "model5.fit(x_train, y_train) # Train/Fit model \n",
    "\n",
    "y_pred5 = model5.predict(x_test) # get y predictions\n",
    "print(classification_report(y_test, y_pred5)) # output accuracy\n",
    "\n",
    "\n",
    "test_score = accuracy_score(y_test, model5.predict(x_test)) * 100\n",
    "\n",
    "results_df_2 = pd.DataFrame(data=[[\"Decision Trees\", test_score]], \n",
    "                          columns=['Model', 'Accuracy %'])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 6: Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model6 = RandomForestClassifier(max_depth=4,random_state=42)# get instance of model\n",
    "model6.fit(x_train, y_train) # Train/Fit model \n",
    "\n",
    "y_pred6 = model6.predict(x_test) # get y predictions\n",
    "print(classification_report(y_test, y_pred6)) # output accuracy\n",
    "\n",
    "\n",
    "test_score = accuracy_score(y_test, model6.predict(x_test)) * 100\n",
    "\n",
    "results_df_2 = pd.DataFrame(data=[[\"Random Forest\", test_score]], \n",
    "                          columns=['Model', 'Accuracy %'])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 7:  XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model7 = XGBClassifier(random_state=1)\n",
    "model7.fit(x_train, y_train)\n",
    "y_pred7 = model7.predict(x_test)\n",
    "print(classification_report(y_test, y_pred7))\n",
    "\n",
    "\n",
    "test_score = accuracy_score(y_test, model7.predict(x_test)) * 100\n",
    "\n",
    "results_df_2 = pd.DataFrame(data=[[\"XGboost\", test_score]], \n",
    "                          columns=['Model', 'Accuracy %'])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get importance\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "imps = permutation_importance(model4, x_test, y_test)\n",
    "arr=imps.importances_mean\n",
    "col=data.columns[:-1]\n",
    "\n",
    "for i in range(12):\n",
    "    print(\"feature\",col[i],\"has score:     \",arr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_score = arr\n",
    "\n",
    "index = data.columns[:-1]\n",
    "\n",
    "df = pd.DataFrame({'Feature Score': feature_score}, index=index)\n",
    "\n",
    "ax = df.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the Feature Importance graph above, we can conclude that the top 4 significant features were chest pain type (cp), maximum heart rate achieved (thalach), number of major vessels (ca), and ST depression induced by exercise relative to rest (oldpeak). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: A patient develops cardiac symptoms & you input his vitals into the Machine Learning Algorithm. \n",
    "\n",
    "He is a 20 year old male, with a chest pain value of 2 (atypical angina), with resting blood pressure of 110. \n",
    "\n",
    "In addition he has a serum cholestoral of 230 mg/dl. \n",
    "\n",
    "He is fasting blood sugar > 120 mg/dl. \n",
    "\n",
    "He has a resting electrocardiographic result of 1. \n",
    "\n",
    "The patients maximum heart rate achieved is 140.\n",
    "\n",
    "Also, he was exercise induced angina.\n",
    "\n",
    "His ST depression induced by exercise relative to rest value was 2.2.\n",
    "\n",
    "The slope of the peak exercise ST segment is flat. \n",
    "\n",
    "He has no major vessels colored by fluoroscopy,\n",
    "and in addition his maximum heart rate achieved is a reversable defect.\n",
    "\n",
    "Based on this information, can you classify this patient with Heart Disease?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model4.predict(sc.transform([[20,1,2,110,230,1,1,140,1,2.2,2,0,2]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model for use\n",
    "# save the model to disk\n",
    "import pickle\n",
    "pickle.dump(model, open('model4', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}